import pandas as pd
from pathlib import Path
import re
import html

# ========== é…ç½® ==========
BASE_DIR = Path(__file__).resolve().parent.parent
RAW_DIR = BASE_DIR / "data" / "raw" / "pubmed"
OUT_DIR = BASE_DIR / "data" / "processed"
OUT_DIR.mkdir(parents=True, exist_ok=True)

OUT_FILE = OUT_DIR / "pubmed_segments.csv"


def clean_text(text: str) -> str:
    """
    å­¦æœ¯çº§æ–‡æœ¬æ¸…æ´—å‡½æ•°ï¼š
    1. è½¬ä¹‰ HTML å­—ç¬¦ (å¦‚ &gt; -> >)
    2. å»é™¤ HTML æ ‡ç­¾ (å¦‚ <i>, <b>, <sub>)
    3. å»é™¤ URL é“¾æ¥
    4. è§„èŒƒåŒ–ç©ºç™½å­—ç¬¦
    """
    if not isinstance(text, str):
        return ""

    # 1. HTML è§£ç 
    text = html.unescape(text)

    # 2. å»é™¤ HTML æ ‡ç­¾ (ä¿ç•™æ ‡ç­¾å†…çš„å†…å®¹ï¼Œåªå»æ ‡ç­¾æœ¬èº«)
    text = re.sub(r'<[^>]+>', '', text)

    # 3. å»é™¤ URL (http/https å¼€å¤´)
    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)

    # 4. æ›¿æ¢å„ç§å¥‡æ€ªçš„ç©ºç™½ç¬¦ä¸ºå•ä¸ªç©ºæ ¼
    text = re.sub(r'\s+', ' ', text)

    return text.strip()


def main():
    print("ğŸš€ å¼€å§‹æ‰§è¡Œæ•°æ®é¢„å¤„ç†...")
    all_rows = []

    # 1. éå†æ‰€æœ‰ raw æ•°æ® (pubmed_dm_cvd_5y.csv)
    csv_files = list(RAW_DIR.glob("*.csv"))
    if not csv_files:
        print("âŒ æœªæ‰¾åˆ°åŸå§‹æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œ fetch_pubmed.py")
        return

    for csv_path in csv_files:
        print(f"æ­£åœ¨å¤„ç†æ–‡ä»¶: {csv_path.name} ...")
        try:
            df = pd.read_csv(csv_path)
        except Exception as e:
            print(f"âš ï¸ è¯»å–å¤±è´¥ {csv_path}: {e}")
            continue

        # ç»Ÿè®¡å¤„ç†å‰æ•°é‡
        original_count = len(df)

        # 2. æ ¸å¿ƒæ¸…æ´—é€»è¾‘
        # å¡«å……ç©ºå€¼
        df["title"] = df["title"].fillna("")
        df["abstract"] = df["abstract"].fillna("")

        # åº”ç”¨æ¸…æ´—å‡½æ•°
        df["title_clean"] = df["title"].apply(clean_text)
        df["abstract_clean"] = df["abstract"].apply(clean_text)

        # 3. è¿‡æ»¤æ— æ•ˆæ•°æ®
        # è§„åˆ™ï¼šæ‘˜è¦é•¿åº¦å¿…é¡» > 50 å­—ç¬¦ï¼Œä¸”æ ‡é¢˜ä¸ä¸ºç©º
        df = df[(df["abstract_clean"].str.len() > 50) & (df["title_clean"].str.len() > 5)]

        print(f"  - æ¸…æ´—å‰: {original_count} æ¡ -> æ¸…æ´—å: {len(df)} æ¡")

        # 4. æ ¼å¼åŒ–è¾“å‡º
        for _, row in df.iterrows():
            pmid = str(row["pmid"])
            # ç»„åˆæ–‡æœ¬ï¼šTitle. Abstract
            full_text = f"{row['title_clean']}. {row['abstract_clean']}"

            all_rows.append({
                "segment_id": f"pub_{pmid}",  # å”¯ä¸€æ ‡è¯†ç¬¦
                "pmid": pmid,
                "year": row.get("year", ""),
                "disease_group": row.get("disease_group", "chronic"),
                "text": full_text,
                "source": "pubmed"
            })

    # 5. ä¿å­˜ç»“æœ
    if all_rows:
        result_df = pd.DataFrame(all_rows)
        # æŒ‰ pmid å»é‡ï¼ˆé˜²æ­¢å¤šæ¬¡æŠ“å–å¯¼è‡´çš„é‡å¤ï¼‰
        result_df.drop_duplicates(subset=["pmid"], inplace=True)

        result_df.to_csv(OUT_FILE, index=False)
        print(f"\nâœ… é¢„å¤„ç†å®Œæˆï¼")
        print(f"   - æ€»æœ‰æ•ˆæ•°æ®é‡: {len(result_df)} æ¡")
        print(f"   - ç»“æœå·²ä¿å­˜è‡³: {OUT_FILE}")

        # æ‰“å°ä¸€æ¡æ ·ä¾‹ï¼Œæ–¹ä¾¿ä½ æ£€æŸ¥è´¨é‡
        print("\nğŸ“ æ ·ä¾‹æ•°æ® (å‰ 100 å­—ç¬¦):")
        print(result_df.iloc[0]["text"][:100] + "...")
    else:
        print("\nâš ï¸ æ²¡æœ‰ç”Ÿæˆä»»ä½•æœ‰æ•ˆæ•°æ®ï¼Œè¯·æ£€æŸ¥åŸå§‹ CSV æ–‡ä»¶ã€‚")


if __name__ == "__main__":
    main()